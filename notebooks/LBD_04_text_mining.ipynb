{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LBD Text Mining Module\n",
    "\n",
    "This module implements various text mining algorithms like topic modeling, sentiment analysis, and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import csr_matrix\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from typing import List, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function perform_topic_modeling takes a document-term matrix in the Compressed Sparse Row (CSR) format and an integer \n",
    "specifying the number of topics to extract as input, and uses the scikit-learn library to perform topic modeling using \n",
    "Latent Dirichlet Allocation (LDA). \n",
    "The function first creates an instance of the sklearn.decomposition.LatentDirichletAllocation class \n",
    "with the specified number of components and a fixed random state of 42 for reproducibility.\n",
    "\n",
    "The function then fits the LDA model to the input document-term matrix and transforms it into a document-topic matrix \n",
    "using the lda.fit_transform() method.\n",
    "\n",
    "Finally, the function returns a tuple containing the LDA model and the document-topic matrix as a NumPy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_topic_modeling(matrix: csr_matrix, n_topics: int) -> Tuple[BaseEstimator, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform topic modeling on a document-term matrix using Latent Dirichlet Allocation (LDA).\n",
    "    :param matrix: csr_matrix, the document-term matrix to perform topic modeling on\n",
    "    :param n_topics: int, the number of topics to extract\n",
    "    :return: Tuple[BaseEstimator, np.ndarray], the fitted topic modeling LDA model and the document-topic matrix\n",
    "    \"\"\"\n",
    "    # Create an instance of the LatentDirichletAllocation class from scikit-learn\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "\n",
    "    # Fit the LDA model to the document-term matrix and transform it into a document-topic matrix\n",
    "    document_topic_matrix = lda.fit_transform(matrix)\n",
    "\n",
    "    # Return the LDA model and the document-topic matrix as a tuple\n",
    "    return lda, document_topic_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function perform_sentiment_analysis takes a list of tokenized text documents as input and uses \n",
    "the Natural Language Toolkit (NLTK) library to perform sentiment analysis using \n",
    "the VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool. \n",
    "The function first ensures that the required NLTK data for the VADER sentiment analysis tool \n",
    "is downloaded using the nltk.download() method with the quiet=True argument to suppress download messages.\n",
    "\n",
    "The function then creates an instance of the nltk.sentiment.SentimentIntensityAnalyzer, \n",
    "which is an implementation of the VADER sentiment analysis algorithm. \n",
    "The function initializes an empty list sentiment_scores to store the sentiment scores for each document.\n",
    "\n",
    "For each document in the input tokens_list, the function calculates the sentiment score by first joining \n",
    "the tokens into a single string using the join() method. The function then calculates the sentiment score for the document \n",
    "using the SentimentIntensityAnalyzer's polarity_scores() method, which returns a dictionary containing \n",
    "the sentiment scores for the positive, negative, neutral, and compound sentiment components. \n",
    "The function appends the compound sentiment score to the sentiment_scores list.\n",
    "\n",
    "Finally, the function returns the list of sentiment scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sentiment_analysis(tokens_list: List[List[str]]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on a list of tokenized text documents using the VADER sentiment analysis tool from NLTK.\n",
    "    :param tokens_list: List[List[str]], a list of tokenized text documents\n",
    "    :return: List[float], a list of sentiment scores for each document\n",
    "    \"\"\"\n",
    "    # Ensure the NLTK data is downloaded\n",
    "    nltk.download('vader_lexicon', quiet=True)\n",
    "    \n",
    "    # Create an instance of the SentimentIntensityAnalyzer from NLTK\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Initialize an empty list to store the sentiment scores\n",
    "    sentiment_scores = []\n",
    "\n",
    "    # Calculate the sentiment scores for each document in the tokens_list\n",
    "    for tokens in tokens_list:\n",
    "        # Join the tokens into a single string\n",
    "        document = ' '.join(tokens)\n",
    "        \n",
    "        # Calculate the sentiment score using the SentimentIntensityAnalyzer\n",
    "        sentiment = sia.polarity_scores(document)\n",
    "        \n",
    "        # Append the compound sentiment score to the sentiment_scores list\n",
    "        sentiment_scores.append(sentiment['compound'])\n",
    "\n",
    "    return sentiment_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function perform_clustering takes a document-term matrix in the Compressed Sparse Row (CSR) format and \n",
    "an integer specifying the number of clusters to create as input, and uses the scikit-learn library \n",
    "to perform clustering using the K-Means algorithm. The function first creates an instance \n",
    "of the sklearn.cluster.KMeans class with the specified number of clusters and a fixed random state of 42 for reproducibility.\n",
    "\n",
    "The function then fits the K-Means model to the input document-term matrix using the kmeans.fit() method. \n",
    "After fitting the model, the function obtains the cluster labels for each document using the kmeans.labels_ attribute.\n",
    "\n",
    "Finally, the function returns a tuple containing the K-Means model and the cluster labels as a NumPy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(matrix: csr_matrix, n_clusters: int) -> Tuple[BaseEstimator, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform clustering on a document-term matrix using K-Means.\n",
    "    :param matrix: csr_matrix, the document-term matrix to perform clustering on\n",
    "    :param n_clusters: int, the number of clusters to create\n",
    "    :return: Tuple[BaseEstimator, np.ndarray], the KMeans fitted clustering model and the cluster labels for each document\n",
    "    \"\"\"\n",
    "    # Create an instance of the KMeans class from scikit-learn\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "    # Fit the KMeans model to the document-term matrix\n",
    "    kmeans.fit(matrix)\n",
    "\n",
    "    # Obtain the cluster labels for each document\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # Return the KMeans model and the cluster labels as a tuple\n",
    "    return kmeans, cluster_labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
